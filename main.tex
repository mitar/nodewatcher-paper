
\documentclass[5p,sort&compress]{elsarticle}

\usepackage{latexsym}
\usepackage{amsfonts,amsmath,amssymb}
\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{fancyref}
\usepackage{url}
\usepackage{mathtools}
\usepackage{booktabs}
\usepackage[flushleft]{threeparttable}
\usepackage[english]{babel}
\usepackage[shortcuts]{extdash}
\usepackage{minted}
\usepackage[inline]{enumitem}
\usepackage[labelformat=simple]{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage[draft]{todonotes}

\captionsetup[table]{format=plain,labelformat=simple,justification=centering, labelsep=newline, singlelinecheck=false, textfont={sc}}

\bibliographystyle{elsarticle-num-names}

\hyphenpenalty=750
\hbadness=1350
\frenchspacing

\def\topfraction{0.9}
\def\bottomfraction{0.4}
\def\floatpagefraction{0.8}
\def\textfraction{0.1}

\sloppy
\flushbottom

\newcommand{\nodewatcher}{\textit{nodewatcher}}
\newcommand{\wlanslovenija}{\textit{wlan slovenija}}

\begin{document}

\begin{frontmatter}
% TODO: Do we want some "organic" title? Growing and stuff?
% perhaps something like this:
% TODO: We need better term than "platform"
\title{\nodewatcher{}: A Substrate for Growing Your own Community Networks}
%\title{nodewatcher: enabling simple provisioning, deployment and monitoring of community networks}

\author[fri,wlansi]{Jernej Kos\corref{cor}}
\ead{jernej.kos@fri.uni-lj.si}

\author[berkeley,wlansi]{Mitar Milutinović}
\ead{mitar@tnode.com}

\author[fri,wlansi]{Luka Čehovin}
\ead{luka.cehovin@fri.uni-lj.si}

\cortext[cor]{Corresponding author}

\address[fri]{University of Ljubljana, Faculty of Computer and Information Science, Ljubljana, Slovenia}

\address[berkeley]{University of California, Berkeley, USA}

\address[wlansi]{\wlanslovenija{}, Open wireless network of Slovenia, \url{https://wlan-si.net}}

\begin{abstract}
TBD.
\end{abstract}

\begin{keyword}
community networks \sep management \sep provisioning \sep monitoring \sep wireless \sep mesh \sep collaboration
\end{keyword}
\end{frontmatter}

\section{Introduction}

Community (wireless) networks \cite{Bruno_2005} provide independent, community-owned network infrastructure for user communication and data exchange.
They are mostly built using standard wireless (IEEE802.11) infrastructure \cite{Akyildiz_2005}, by laying own optical fiber and, more recently, by the use of free-space optical systems \cite{Mustafa_2013}.
They use, reuse and repurpose existing communication technologies, like inexpensive off-the-shelf WiFi routers, to form a widespread network.
These networks can cover all from local neighborhoods \cite{RedHook_2013}, to cities \cite{AWMN} and countries \cite{wlanslovenija_2009, guifi_2003, Funkfeuer_2003, Freifunk_2003}.
Their common aim is to empower people with new ways of communication and access to the wider public networks like the Internet.
Motivations for such networks are diverse and multiplex, but often networks are formed out of necessity \cite{WNDW_2013}.
Even in developed countries many rural areas are underserved with Internet connectivity infrastructure built and offered by traditional Internet Service Providers, population density being too low for investments to be profitable enough, leaving to people themselves to build needed infrastructure to connect to the Internet.

The common property of all community networks is that they grow organically~-- there is no central planning body that would decide how the network is built, as is usually the case with proprietary networks.
Instead, the network grows in a bottom-up fashion as more people express interest in participating in the community and connect with their neighbours.

Because of this growth pattern and community involvement, management of such networks poses some unique challenges:

\begin{itemize}
\item In most of the community networks, people who maintain the network infrastructure are volunteers with limited free time that they can spend on network management.
This makes efficient management very important for network growth.
Besides efficiency, an important factor in increasing growth is also the accessibility of network management functions to users who do not have deep technical knowledge of networking specific to mesh networks.

\item There are many repetitive tasks in community network operation, especially related to configuration, deployment and monitoring of network equipment.
Without a suitable overall management system, all these steps (flashing\footnote{Flashing is the process of reprogramming the wireless network device with an unofficial firmware image, commonly Linux based.} and configuring devices, allocating resources, diagnosing problems) need to be done manually which is time-consuming and prone to errors.

\item In addition to technical issues related to device deployment, there is also the need for community coordination so that people know what is going on in the network and can familiarize themselves better with its operation and what others are doing.
In general it is not possible to anticipate how, when, and where a new participant will start participating by deploying one of network's nodes\footnote{Meaning of a ``network node'' is understood differently in different communities. For the purpose of this paper it is used as one routing network device, and as a basic unit of participation by participants.}.

\item For volunteers it is important to have feedback on how they themselves are contributing to the network.
Is the node that they are maintaining highly used and crucial for the part of the network and users?
Volunteers are often motivated by the value they are contributing to the network as a whole, but even when their node is not highly used at the moment, having an insight into operation of the node is important for them to understand that their contribution is something tangible and real, especially for less technically skilled volunteers who might otherwise perceive the node as a black box.
\end{itemize}

Various solutions have appeared in an attempt to address these challenges, each community developed its own model of operation with its own accompanying set of tools.
The problem with this approach is that work is being duplicated between communities and that these various solutions are mostly not interoperable between each other.
So why would new communities not reuse existing tools?
The problem lies in the fact that these tools have not been built to be customized to the needs and operation of individual communities.
Each community has slight differences in their vision and operation philosophy, technological stack they are using and technical knowledge they have, or even legal requirements, and this requires customization on several fronts, to only name a few:
\begin{enumerate*}[label=\itshape\alph*\upshape)]
\item different routing protocols may be used;
\item used WiFi equipment and its operating systems can vary widely between networks;
\item some communities use VPN tunnels to establish certain long-range links using different VPN protocols;
\item network topologies may differ among communities, some use central clusters of nodes as gateways to peer with other networks, some use a more distributed topology;
\item some communities attach various sensors to nodes and would like to monitor their outputs through time;
\item networks can decide to use a captive portal and/or choose to require users to pay to use the network;
\item there may be differences in operation due to local regulations.
\end{enumerate*}

In order to address this, there are at least two approaches that can be taken.
The first one is \textit{the large common base approach} which tries to create a common system that addresses the needs of as many of communities as possible by providing a large feature set and a large configuration schema\todo[inline]{Is the term schema well understood in the community? Should we define it more?} encompassing all possible scenarios.
This approach has been tried as part of an interoperability effort \cite{interop_2010, cnml_2007} established between community networks, to come up with a common schema upon which so called node databases could be built.
The problem is that it is hard to come up with a one-fits-all solution and large monolithic schemas can quickly become unmanageable.
Moreover, it requires sustained effort from participating community networks first to establish the standard and then to keep it updated as technologies and practices evolve.
Because community networks are mostly volunteer run, such sustained participation is unattainable for many community networks.
Additionally, it is practically impossible to involve all community networks in this process and there are always new networks with new differences.
This process favours large and established network communities.

The other way is \textit{the extensible core approach} where the aim is to create a minimal core with highly modular and extensible design so that community networks can tailor it to their needs, whatever they might be.
This is the approach that we are taking with the \nodewatcher{} v3\todo[inline]{Should we mention that this a rewrite of existing nodewatcher v2?} platform.
We make the following novel contributions:
\begin{itemize}
\item A modular open platform that may be easily tailored to the needs of any community network.
\item An extensible per-node firmware image generation system that enables generation of pre-configured images for specific nodes in order to eliminate any manual configuration requirement on the nodes.
\item An extensible monitoring system with a scalable time-series data storage backend enabling large-scale collection of status and other telemetry data while supporting interactive visualizations.
\item User interface designed and structured so that it is suitable both for novice and expert users, tailored for collaboration and coordination of volunteers.
\end{itemize}

The rest of this paper is organized as follows.
Section~\ref{sec:related-work} presents related work done in the area of community network management tools.
Section~\ref{sec:platform} presents the design and functioning of the \nodewatcher{} platform.
Section~\ref{sec:evaluation} shows the results of platform evaluation in the \wlanslovenija{} community wireless network.
Section~\ref{sec:conclusion} presents conclusions and ideas for future work.

\section{Related Work}
\label{sec:related-work}

A lot of research has been done into individual wireless mesh network building blocks. Among them are routing~\cite{Murray_2010,Neumann_2012}, security~\cite{Siddiqui_2007}, and analysis of topologies, performance, mobility~\cite{Vega_2012,Zakrzewska_2008}.
But research into community network management solutions and best practices still remains scarce.
This is why most of the related work in this area comes from the individual community networks which have each developed its own solutions, practices and philosophy.

In this section we survey the most visible network management solutions, traditional ones and specialized solutions developed by community networks worldwide.
We compare them to the approach taken by \nodewatcher{} platform.

\subsection{Traditional Network Management}

There are many existing network management systems, suited for more traditional (non-community) networks~\cite{Cacti_2004,Nagios_1999,Zabbix_2004,Puppet_2005,Salt_2011}.
By their management function, they can be segmented into two major classes as follows:
\begin{description}
\item[Monitoring systems] enable the operators to remotely monitor a set of devices to see whether they are reachable and to get some insights into their operation.
Some of these systems can generate events and notify the operators when errors are detected, while others can only visualize the data without interpreting it.

\item[Configuration management systems] enable the operators to maintain a central repository of device configurations that can be used to provision devices.
In these systems, configuration is mostly input using a domain-specific or a scripting language and deployment is done using remote agents that interpret configuration scripts and apply configurations.
\end{description}

While these systems can be used in community networks, they are not tailored to their specific needs.
First, some of the monitoring and configuration management systems require agents which consume too much resources to run on simple off-the-shelf network equipment commonly in use in community networks.
They might be suitable to monitor some better-equipped network nodes, but would require different systems for managing other parts of the network, which increases the work load of volunteer participants.
Additionally, these systems are independent solutions, requiring manual integration which needs to be performed by each community.
This increases the chance that each community will pick different solutions and end up with systems which are not interoperable with other.
Configuration management systems are not suitable for embedded systems, or if they are, they target devices of a particular manufacturer, and not a diverse range of often customized devices found in community networks.

But most importantly, since they have not been designed with community networks in mind, none of these systems provide community coordination capabilities.
They are highly technical to setup and use, which makes it harder to properly configure by community without highly skilled members.
They are designed for general networks and do not encode experiences and particularities of community networks in their source code, which would help new community networks to start with reasonable and tested defaults and configurations.
Reading information from monitoring systems is designed for trained network operators and ways of entering configuration management systems requires high understanding of computer networks terminology and operation.
They are often developed as an independent codebase which makes it much harder to integrate with other open source solutions used by a community network, like community management solutions, and they lack one unified interface, which further confuses novice users.

\subsection{Node Databases}

Many wireless mesh network communities have quickly recognized the need for having a central system that would be able to manage the growing number of wireless mesh nodes.
One of the oldest and largest mesh networks are Guifi.net \cite{Guifinode_2003,Vega_2012} and the Athens Wireless Metropolitan Network~\cite{AWMN_WIND_2002}.
As the node database solutions evolved with the respective networks, both are tailored to specific structures of their networks and its management structure.
Their codebase is monolithic, making it hard to extend with new features or customizations.
This applies to the schema (which lacks any kind of object-relational mapping~\cite{ONeil_2008} and is therefore hard to manage when developing extensions), frontend interface and core functionalities.
The node database solutions are build on custom web frameworks, further limiting the ease of adoption by a new community network.
Additionally, advanced network monitoring functionality is missing, requiring the use of external utilities, which causes duplication of configuration and is an error-prone process (see Section~\ref{sec:network-monitoring}).

Two more recent representatives of community network node databases are Nodeshot~\cite{Nodeshot_2012} and Freifunk FFM/CNDB~\cite{Funkfeuer_2012}, developed by Ninux and Freifunk community networks, respectively.
Nodeshot is an extensible web application for management of community geographic data.
It focuses on mapping features with a more modular approach where various functionalities are extracted into modules.
The modularity makes extending the application easier, but in contrast to \nodewatcher{}, there is no common approach to managing schema extensions and interfaces between modules are still tightly coupled.
There is some monitoring support, but it is mostly limited to device discovery in an existing network and is not meant for long-term monitoring and diagnostics.

Freifunk FFM/CNDB features an extensive database schema which models everything from devices to companies and people.
With its very detailed modelling of individual objects it is an example of the large common base approach.
Similar to Nodeshot, there is no common approach to managing schema extensions and there is also no monitoring support.
It uses a custom web framework with almost nonexistent documentation, having a steep learning curve before extending and adapting the system to another community network is possible.

None of the existing solutions support generating functional and pre-configured firmware images that can be directly flashed to devices, reducing the required administration burden and making the whole process easier for novices.
As a consequence, they do not support comparing running configuration with provisioned one and detecting misconfiguration and unwanted changes.
This makes detecting possible issues in advance impossible, and debugging issues once they occur slower.

\section{Platform}
\label{sec:platform}

The design and development of the \nodewatcher{} platform comes from the needs and evolution of the \wlanslovenija{} community wireless network.
We have come across the problems outlined above and the \nodewatcher{} platform has been designed to be maximally extensible and reusable among different communities.
This section describes all the components of the platform, beginning with a quick high-level overview of the architecture.

\subsection{Overview}

\begin{figure}
  \centering
  \includegraphics[scale=0.4]{figures/device-mgmt-cycle.pdf}
  \caption{Device management cycle illustrating how devices are managed in a community network.
Traditionally the configuration, generation and monitoring steps are performed manually, while the \nodewatcher{} platform enables automation of these tasks, freeing up resources inside a community.}
  \label{fig:device-mgmt-cycle}
\end{figure}

% TODO: Po mojem bi morali tu dati nekje tudi cloveka v diagram. Ker sicer izgleda tako tehnicno. V smislu, ce je community network, kje je community v tem ciklu?

The core idea behind the \nodewatcher{} platform is the \textit{device management cycle}, illustrated by Figure~\ref{fig:device-mgmt-cycle}.
The cycle starts with the \textit{configuration stage} where devices are configured for use in a specific location in the network.
At this stage, device configuration is still platform-independent and does not depend on the hardware that will be later used to deploy the device.
The latter only happens in the next stage, the \textit{generation stage}, where platform-independent configuration is transformed to device- and platform-specific configuration.
For easier deployment, a firmware image for the target device may also be generated.
Then, in the \textit{deployment stage}, configuration or firmware is applied to the target device and the device is deployed in the field.
As soon as the device is deployed and is able to join the network, it is monitored by the platform.
In the \textit{monitoring stage}, the device is actively validated for correct operation in context of the whole network.
In case errors in configuration or other problems are detected, the device's maintainer is notified so the device may be fixed and/or reconfigured, repeating the cycle.

The \nodewatcher{} platform aims to provide components for all stages of the described device management cycle.
Each part is designed to be easily extensible to networks with various topologies, routing protocols, operating systems and hardware devices.

\subsection{Platform-independent Configuration}

Community networks are built using a wide range of devices, containing everything from off-the-shelf home routers to specialized devices used for backbone links and regular servers used for core services.
The \nodewatcher{} platform uses a single platform-independent schema to describe configuration for all these types of nodes, regardless of their hardware and/or operating system.
One of the motivations behind this choice is that platform-independent configuration enables replacement of devices without the need to do much re-configuration.
It is a frequent occurrence that deployed devices need to be replaced when they stop functioning properly due to various hardware failures.

However, while having a platform-independent configuration is a noble goal, some configuration properties inherently depend on features which are inherently device-dependent (for example the number of Ethernet ports, available wireless radios, supported protocols, etc.).
In such cases the user editing the platform-independent configuration may create a configuration which will fail to work when applied to the target device.
This can further delay problem discovery until the \textit{deployment} stage when it is already too late and costly to fix problems, especially in wireless networks where nodes may be deployed in hard-to-reach locations.
This clearly shows the need to have instant validation and feedback (the \textit{feedback} arrow in Figure~\ref{fig:device-mgmt-cycle}) when updating platform-independent configuration.
Such validation must be based on the selected target device with all its hardware and software properties.
The \nodewatcher{} platform enables instant validation which is handled by the firmware generator component (see Section~\ref{sec:firmware-generator}).

In the introduction we mentioned the problem with attempting to design an all-encompassing schema or a single node database application that would cover every possible deployment of community networks.
Communities will usually have some specifics regarding their operations~-- either because of different local regulations or differences in philosophy.
Having a single unified schema can quickly become a limiting factor that prohibits straightforward adaptation of the system for the local community.

\begin{figure}
\centering
\begin{minted}[fontsize=\small,frame=single,framesep=2mm]{python}
class VIFConfig(InterfaceConfig, RoutableInterface):
  device = IntraRegistryForeignKey(
    WifiRadioDeviceConfig,
    related_name='interfaces'
  )

  mode = ChoiceField('core.interfaces#wifi_mode')
  essid = CharField()
  bssid = MACAddressField()

# Register schema item into the schema which makes
# it available to any other module.
registration.point('node.config').register_subitem(
  WifiRadioDeviceConfig, VIFConfig)
\end{minted}
\caption{A simplified example of a platform-independent schema definition for a virtual wireless interface configuration extended from two base classes \texttt{InterfaceConfig} and \texttt{RoutableInterface}.}
\label{fig:schema-module-wifi}
\end{figure}

The \nodewatcher{} platform avoids this problem by making the platform-independent schema itself completely extensible.
It is the individual modules that may register schema items and the final schema is the union of all these items.
An example of a schema item definition is shown in Figure~\ref{fig:schema-module-wifi}, where several properties of the schema extension mechanism can be shown:
\begin{itemize}
    \item The schema items are class-based, which means they can be extended later on by other modules (in the example the \texttt{VIFConfig} extends a more generic \texttt{InterfaceConfig} which may be provided by another module).
    \item Fields that represent enumerations (in the example \texttt{mode} is such a field) do not hardcode the possible options, but only provide an \textit{extension point} where additional choices can later be registered by other modules.
    Each such extension point is attached to a unique name (e.g. \texttt{core.interfaces\#wifi\_mode}) that may be referenced later when extending it.
    \item Schema items may reference other items (in the example, \texttt{device} references the parent radio device that this virtual wireless network configuration is being configured on).
\end{itemize}

To construct the base schema that is available with the \nodewatcher{} platform, we have surveyed all the different solutions mentioned in Section~\ref{sec:related-work} and included a small amount of items common to most of the communities.
But even these base schema items are just module registrations which makes them removable in case some community needs to really change how things work.

The system that supports such schema item registrations is called the \textit{registry} and is essentially a lightweight extension of the standard object-relational mapper (ORM) concept~\cite{Bernstein_2007,ONeil_2008} as the mentioned schema items are actually models.
The problem that it aims to solve is the one of simplified model discovery. In an extensible platform like \nodewatcher{}, modules may want to query on fields defined by other modules somewhere in the schema. For example, there may be a schema item called \texttt{InfoCfg} in the base schema, enabling users to configure a \texttt{name} for a node:

\begin{minted}[fontsize=\small]{python}
class InfoCfg(NodeConfigRegistryItem):
  name = CharField()
  
  class Meta:
    registry_id = 'info'
\end{minted}

This base item does not provide any other fields besides the node name, leaving potential extensions to other modules.
Let us now say that we would like to also add a simple text field which would specify what device is in use on a specific node (in reality, we would more likely use a choice field, but for our example a simple text field suffices). We may do that in another module by saying:
\begin{minted}[fontsize=\small]{python}
class ExtendedCfg(InfoCfg):
  device = CharField()
\end{minted}

Imagine now another module that would like to perform a query listing only nodes that use a device called \texttt{tp-wr741ndv4}.
As mentioned, these two classes actually represent ORM model definitions so a traditional query traversing these two relations would go something like this using the SQL-like relational query notation introduced in~\cite{ONeil_2008}:
\begin{minted}[fontsize=\small]{sql}
SELECT n FROM Node n
WHERE n.infocfg.extendedcfg.device = 'tp-wr741ndv4'
\end{minted}

Here we make the assumption that there is a one-to-one relation between a \texttt{Node} and \texttt{InfoCfg}.
While one-to-many relations are also supported (so each node can have multiple instances of a model), we limit ourselves to this simple case for ease of exposition.
Note how even in this very simple example we had to explicitly specify the hierarchical path that is spanning these two relations to get to the wanted field.
This makes such a method not very developer-friendly under the requirement of extensibility and even more complex schemas.
One of the features that the registry enables, is that we can simplify the same query as:
\begin{minted}[fontsize=\small]{sql}
SELECT n FROM Node n
WHERE REGISTRY info.device = 'tp-wr741ndv4'
\end{minted}

In this case, the \texttt{info} is the \textit{registry identifier} that we attached to the base model using its \texttt{Meta} data and represents itself or any of its subclasses at the same time.
In the background, the proper relations are automatically deduced and the query executed.
Similar extensions are also provided for simplified fetching of fields deeply nested in the schema by deducing and performing the required table join operations.

\subsection{Form Generation and Rule-based Defaults}

\begin{figure}[t]
  \centering
  \includegraphics[scale=0.5]{figures/defaults-rules-tree.pdf}
  \caption{Example showing a compacted expression tree for specification of context-sensitive defaults for a wireless ESSID configuration. Hexagons are rule condition expressions while squares are action expressions.}
  \label{fig:defaults-rules-example}
\end{figure}

\begin{figure*}
  \centering
  \includegraphics[scale=0.5]{figures/firmware-buildsystem.pdf}
  \caption{An overview of the firmware build system, coming from platform-independent configuration in the first stage to the fully configured firmware image that may be flashed directly onto the target device in the final stage.
The firmware builders are Docker containers with pre-built firmware build toolchains.}
  \label{fig:firmware-build-system}
\end{figure*}

Having an extensible schema is a nice step towards reusable modules shared between community networks.
But a schema is useful just for module developers so that they have a place to store various configuration values.
For platform users, the frontend (web interface) is even more important.

There are two issues regarding user interaction with the configuration schema:
\begin{enumerate*}[label=\itshape\alph*\upshape)]
\item there must be a way for the users to enter configuration values conforming to the specified schema;
\item since the schema may be complex, there needs to be a way for project maintainers to be able to codify context-sensitive configuration defaults.
\end{enumerate*}
The first issue is addressed in \nodewatcher{} by the registry API's ability to automatically generate a user interface (forms) conforming to the schema.
Automatic form generation simplifies the module development process and reduces code duplication.
The automatically generated forms may be customized by the module developers where needed, but even defaults are immediately usable for simple schema items.

Addressing the second issue is especially important in order for community networks to be more accessible to people that do not have all the deep technical knowledge on how to configure devices.
Having the ability to define sensible defaults for such users is a feature that enables the community to also include such users.
A possible solution would be for network maintainers to provide pre-defined templates of configuration defaults.
The problem with static templates is that defaults may differ when applied to devices with different capabilities or a different project, in other words the defaults may be context-sensitive.
One would then be required to create static templates for all combinations, which quickly becomes unmanageable due to a combinatorial explosion in the number of required templates.

\nodewatcher{} takes a different approach, enabling codification of defaults in the form of simple declarative rules.
The example in Figure~\ref{fig:defaults-rules-example} shows context-sensitive default wireless ESSID configuration.
Rules in this example only apply to a specific project and configure two virtual interfaces (VIFs), one in mesh mode and the other in access point mode, in case the radio supports them.
In case the radio does not support configuring virtual interfaces, only one network may be set, and in this case a single mesh mode interface is configured.
The benefit of using a declarative approach for specifying rules instead of an imperative one is that the rules may only be evaluated when needed~-- in the above example, the inner rules will be evaluated only when the project changes and not when any other fields in the schema change.
This is an important detail as defaults should not overwrite configuration when changing an unrelated setting.

Evaluation of these rules is achieved by first generating an expression tree and then lazily evaluating only those sub-trees which contain expressions that match the current configuration value change.
In order to detect which rules have already been evaluated, forms generated by the registry contain internal state.

\subsection{Resource Allocation}

As in any network, there is also a need to perform IP address resource allocation in community networks.
This is especially the case in IPv4-based networks where it is hard to automatically generate node addresses without collisions due to the small available space.

In order to support that, \nodewatcher{} implements a hierarchical buddy allocation scheme~\cite{Peterson_1977} extended with support for hold down timers.
At the top level IP space is split into multiple pools from which other objects (for example nodes) may request specific allocations.
Hold down timers are necessary to avoid collisions with nodes that have been recently removed.
When an allocation is freed, it is still marked as \textit{reserved} until the hold down timer expires.

This is required especially in community networks where nodes may not be completely removed and may actually reappear at a later time, causing routing conflicts.

\subsection{Firmware Generator}
\label{sec:firmware-generator}

Traditionally, devices may be configured manually before they are deployed.
This is usually done either through a command-line interface via secure shell (SSH) or a graphical user interface via HTTP, depending on the firmware running on the device.
In both cases, however, this is an error-prone process due to manual user input.
Mistakes can easily happen and sometimes they might propagate to the deployment stage where they are hard and costly to fix.
In community wireless networks, devices are sometimes deployed in hard-to-reach locations like rooftops or high towers and fixing certain problems requires physical access to the device.

As described, the \nodewatcher{} platform can be used to store device configurations in a platform-independent way using the schema items exposed by the registry.
But this configuration cannot directly be used on devices.
Different operating systems like the open source OpenWrt~\cite{OpenWrt_2004} or the proprietary RouterOS~\cite{RouterOS_1995} that are frequently used on devices in community networks, have completely different ways of being configured.
This is why an additional platform-dependent transformation step is needed.

However, such a step presents some additional challenges that prevent a straightforward transformation of any configuration based on the platform-independent schema to a device-specific one.
This is due to the fact that there are differences between operating systems which may prevent certain configurations from being properly instantiated on one operating system even when those same configurations work without issues on another one.
Additionally even using the same operating system, devices have different capabilities due to differences in their hardware.
Configuration which was platform-independent and unaware of the target device in the first stage can produce problems while being applied to a specific device and operating system.
This conflict may result in some unpleasant, but realistic, scenarios:
\begin{enumerate}[label=\roman*)]
\item Devices have different default network switch layouts and VLAN tags.
As usually nodes use the WAN-designated port for the internet uplink and the LAN-designated port for routing to nodes in the same location, such a misconfiguration will cause connectivity issues.

\item Configuration of some wireless authentication mechanisms requires the installation of specialized packages on some operating systems.
Without them even an otherwise valid configuration will simply not work.

\item Different devices have different radio capabilities.
For example, some devices only support IEEE802.11a channels and if the configuration system is not aware of this, blind configuration transformation to the target platform results in a failure to bring up the wireless device.
\end{enumerate}

These scenarios show that supporting informed decisions of the configuration transformation process requires the use of a device database component.
\nodewatcher{} takes a declarative approach to device descriptors which enumerate all the hardware and software properties of a given device.
A declarative descriptor is composed from multiple fields as follows:
\begin{itemize}
\item A unique model identifier in the form of \texttt{tp-wr741ndv1} which identifies a specific version of a device model in the database.

\item A name used for representation of the device in user interfaces together with the name of the manufacturer and a URL to its website.

\item The hardware architecture (eg. \texttt{ar71xx}) used by the CPU of the device.

\item A list of wireless radios embedded on the device.
Each radio contains a unique identifier, a name and a list of supported IEEE802.11 protocols and features.
It also contains a list of physical antenna connectors so that the configuration system may know to which port a specific antenna is attached in case there are multiple antenna ports.

\item A list of ethernet switches connected to the CPU together with VLAN tag information and designation of the ports connected directly to the CPU.

\item A list of ethernet interfaces and their connections to declared switches together with their VLAN tag definitions. 
Different devices have different switch and ethernet port configurations and these two options abstract all of this into simpler identifiers like \texttt{lan0} and \texttt{wan0}.

\item A list of antennas that are included in the device package.
Each antenna contains radio propagation properties which characterize the antenna.
\end{itemize}

Device descriptors may be subclassed in order to simplify definitions of new devices with only slight variations.
This feature greatly improves the time to fully support new devices which is important in the quickly evolving community networks.

\begin{figure*}
  \centering
  \includegraphics[scale=0.5]{figures/monitoring-pipeline.pdf}
  \caption{An overview of the \nodewatcher{} monitoring components. Telemetry data is collected on the devices by \texttt{nodewatcher-agent} modules and is then transported over HTTP to the monitoring pipeline. One of the modules in the pipeline is the datastream processor which stores all the historical data as time series, supporting later interactive visualization through time.}
  \label{fig:monitoring-pipeline}
\end{figure*}

Using these device descriptors and the platform-independent configuration provided in the first stage, \nodewatcher{} is able to generate device-specific configuration using a transformation step (see Figure~\ref{fig:firmware-build-system} for an overview of the whole process).
The transformation step is built from a pipeline of modules where each of them gets the platform-independent configuration as input and may produce modifications to the device-specific configuration as its output.
Such a modular transformation step ensures that the pipeline can be adapted to a wide range of transformations (for example, supporting various routing protocols, sensor inputs, network configurations etc.), so everything that a target device and operating system support may be used.
Recalling the importance of the feedback arrow in Figure~\ref{fig:device-mgmt-cycle}, the transformation module pipeline may also raise errors when parts of the input configuration could not be properly transformed.
These errors are immediately propagated up to the user who is entering configuration via the \nodewatcher{}'s web interface, so that problems may be corrected as soon as possible.
The validation system will not save a configuration which has outstanding errors, preventing invalid configurations from being used to deploy devices.

In order to further ease deployment, the resulting device-specific configuration may be packaged together with a firmware image which may be then flashed directly onto the target device.
Such pre-generated firmware images further reduce the room for errors as no configuration needs to be transferred separately or entered manually.
Besides reducing errors, packaging software (firmware) together with its configuration is also beneficial for ensuring that the configuration really is applicable to the used software versions as both can be tested together.
Otherwise, using a stale configuration on a newer operating system or newer versions of some packages may result in failing devices.
Bundling firmware together with node-specific configuration is a novel way of provisioning devices in community networks  that would be beneficial to existing and emerging networks alike.

The underlying firmware build system has been designed in such a way that it is extensible to different operating systems and platforms.
To achieve this, the build system is structured into multiple Docker containers~\cite{Docker_2013}.
Docker containers are a lightweight wrapper around the Linux namespacing API and filesystem layers with a goal to enable an interface for packaging applications in a reusable and extensible way.
Namespaces provide container isolation (the containers still share the host kernel), so that adjacent containers running on the same host are unable to see or influence each other's processes, network configuration, etc.
Each container can be thought of as a very lightweight virtual instance, but without the overhead of running a full virtual machine with its own kernel.
\nodewatcher{} uses the Docker container features in order to generate and run firmware image builders for multiple platforms.
The build process is specific for each operating system and currently only OpenWrt is supported as it runs on the most devices that are in use in community networks.

When the device-specific configuraion has been generated by the transformation step (see the central node in Figure~\ref{fig:firmware-build-system}), a suitable builder is selected based on the architecture and software platform specified in the device descriptor.
After a builder is identified, the \nodewatcher{} process establishes a secure shell (SSH) connection to the selected container, transfers the configuration there and starts the build process which completes in a matter of seconds.
This decoupling of configuration and firmware builders enables the builder containers to be deployed on another machine with more resources.

By packaging firmware builders as containers, \nodewatcher{} enables simple reuse and sharing of ready-made builders between community networks.
Compiling and preparing a range of firmware builder toolchains can be a lengthy process requiring manual configuration, but such containerized organization enables communities to simply download pre-built toolchains and use them in their \nodewatcher{} instances without compiling anything. The described system is also extensible~-- adding support for new architectures simply requires a new builder container to be prepared, while adding support for new operating systems also requires an extension of the configuration transformation pipeline.

\subsection{Network Monitoring}
\label{sec:network-monitoring}

After the firmware images are prepared and devices are deployed in the field, there is a need to constantly monitor the devices for compliance.
In the same way as the configuration transformation step performs static validation of device configuration before it is deployed, the role of the monitoring component is to perform dynamic validation of device configuration after the device is running.
While validation is common to both, the scope of the latter is much bigger~-- when deployed in a large network, the functioning of one node may also affect other nodes in its vicinity or sometimes even in completely different parts of the network (for example when considering network announce conflicts in routing protocols).
Besides performing configuration compliance validation, monitoring may also be used to collect various sensor data through time.
This is useful for diagnostics under changing network conditions and can also be used to collect various sensor data coming from external sources like temperature, humidity and lightning strike detection sensors.

One may ask why should monitoring be integrated into the provisioning platform?
It is true that existing network monitoring tools could easily be used instead, but an integrated solution enables the monitoring modules to easily perform validation of current device state and behaviour against the static platform-independent configuration that is stored in the provisioning database.
This enables the system to quickly detect configuration errors (for example after someone manually edited configuration on a device) or failure modes (loss of a redundant VPN link only when such a redundant link has been previously configured).
Such capabilities could be replicated using existing systems, but this would require either manual duplication of configuration (an error-prone process) or specific import scripts for the target monitoring system (which is usually not very portable among different communities).
Thus, an integrated monitoring component is key in ensuring ease of deployment and codified transfer of good practices between community networks.
An overview of the monitoring system is given in Figure~\ref{fig:monitoring-pipeline} which shows the data flowing from sources on the devices towards the time series data store and current network state as the sinks.

Data collection starts on the devices and is implemented by the \texttt{nodewatcher-agent} process.
It is a small C application with a minimal core that is able to periodically request the loaded modules to provide their state updates which are then compiled into the current node status and exported in a JSON form to be served via HTTP.
Each module is a shared library which is loaded when the agent process starts.
Having modules as shared libraries enables simple extension of the monitoring agent by third-party packages.
Modules may independently fetch data from external sources providing state like current resource usage reported by the Linux kernel, status of various interfaces, wireless configuration and site survey, connected clients, external sensor input, etc.

\begin{figure}[t]
\centering
\begin{minted}[fontsize=\small,frame=single,framesep=2mm]{json}
{
  "core.general": {
    "_meta": { "version": 4 },
    
    "uuid": "64840ad9-aac1-4494-b4d1-9de5d8cbedd9",
    "hostname": "test-4",
  },
  "core.resources": {
    "_meta": { "version": 2 },
    
    "memory": {
      "total": 32768,
      "free": 24611
    }
  }
}
\end{minted}
\caption{Example part of the JSON schema compiled by the \nodewatcher{} monitoring agent, showing sample output for two monitoring modules.}
\label{fig:monitoring-json-schema}
\end{figure}

As can be seen from its description, the monitoring agent is similar in design to other parts of \nodewatcher{}, with a focus on modularity.
An important feature of a monitoring agent that runs on remote devices is the ability for modules to independently evolve their schema.
In order to add features to existing modules there needs to be a way to version the state schema which is reported back to the monitoring pipeline.
This is especially the case in community networks where there are many different devices with different firmware versions and also with different versions of the monitoring modules.
A single version for all modules is not enough as modules may be developed by different developers, possibly from different community networks and independent schema evolution is required.

Node state compiled by the agent is a structured JSON document where the top level contains one dictionary element for each module with the element's key being the module identifier.
A partial example of such a state is shown in Figure~\ref{fig:monitoring-json-schema}.
Each module element may provide whatever elements it wants to report for the current state.
The agent will automatically create a special \texttt{\_meta} element containing the module metadata~-- currently a module version number.
By inspecting the metadata, the processing pipeline is able to handle multiple versions of the schema for different modules.

\begin{algorithm}[t]
\begin{algorithmic}
\Procedure{MonitoringRun}{$P$}
  \State $W \gets \emptyset$\Comment{Initialize the working set.}
  \State $C \gets \emptyset$\Comment{Initialize the context.}
  \For{$p \in P$}\Comment{Iterate over the pipeline.}
    \If{$p \in P_n$}\Comment{Network processor.}
      \State $\langle W, C \rangle \gets p.\mathrm{process}(W, C)$
    \ElsIf{$p \in P_m$}\Comment{Node processor.}
      \For{$n \in W$}
        \State $C \gets p.\mathrm{process}(n, C)$
      \EndFor
    \EndIf
  \EndFor
\EndProcedure
\end{algorithmic}
\caption{A single monitoring run.}
\label{alg:monitoring-pipeline}
\end{algorithm}

On the backend, the processing of all operations related to monitoring is handled by the monitoring pipeline.
Conforming to the modular philosophy, the pipeline consists of processors which are implemented by modules.
Throughout the execution of the pipeline two pieces of state are maintained: a working set of node instances and a context.
The context can contain arbitrary structured data which is communicated between the different processors.
Working set of nodes represents the instances that next processors will operate on.
When execution of the pipeline begins, the working set is empty.
There are two basic types of processors:
\begin{description}
\item[Network processors $P_n$] are executed once with all nodes in the working set and context as arguments. They may modify both the working set and the context to change the flow of downstream processors.

\item[Node processors $P_m$] are executed for each node in the working set with context as an argument. They may modify the context but not the working set.
\end{description}

Algorithm~\ref{alg:monitoring-pipeline} shows a simplified version of the processing run execution.
As can be seen from the algorithm, the pipeline is completely generic and its content depends entirely on the processor implementations which are provided by modules.
However, the pipeline implementation actually performs some optimizations that cannot be observed in the above pseudocode.
Network processors must be executed serially as each may modify the working set which is part of the state for downstream processors.
But there is no reason why execution of node processors cannot be done in parallel for each node.
Additionally, if there are multiple consecutive node processors which will run on the same working set (note that only network processors may change the working set), they can all be executed inside the same thread, one after the other.
This greatly reduces the amount of context transfer between processes and speeds up the monitoring run execution.

The modular nature of the monitoring pipeline enables different communities to completely adapt it to their own network.
Since the base framework is common to all, modules from different community networks may interoperate inside the same pipeline, increasing code reuse possibilities.

\subsubsection{Time-series Data Storage}

The monitoring pipeline may generate large amounts of time-series data during its operation (for example \wlanslovenija{} has accumulated over 200 GiB of data in the last few years, storing everything from network diagnostics to external sensor data).
As shown in Figure~\ref{fig:monitoring-pipeline}, one of the processors in the pipeline can be a \textit{datastream} processor, storing time-series data.
Datastream is a system we developed, enabling storage, processing and retrieval of time-series data.
In contrast to round-robin databases~\cite{Oetiker_1999}, where the database size is fixed in advance and old data is simply discarded, we are taking a different approach, storing all the data that we can for possible later analysis.

\begin{figure}
  \centering
  \includegraphics[scale=0.4]{figures/datastream-storage.pdf}
  \caption{Datastream stream storage organization. Tag based metadata store compact indices into the stream data, downsampled at different granularities.}
  \label{fig:datastream-storage}
\end{figure}

The database is built around a concept of streams, each stream being an independent time series.
In order to organize the streams, each stream may be tagged using arbitrary key-value pairs (see Figure~\ref{fig:datastream-storage}), which are indexed and can be used for fast lookup of streams matching specific tags.
For stream storage to be efficient, datums are stored in separate collections, one for each time granularity, and connected with their metadata entries using compact indices.

Each stream has some special tags which define its base operation.
Streams are typed, meaning that they may be used for storage of different datapoint types.
Supported types currently include numeric values (integers, floats, arbitrary precision numbers) and graph values (nodes and edges for storing how topologies evolve over time).
Streams also define the highest granularity at which datapoints will be inserted.
This setting is an optimization which allows the datastream storage backend to reduce the number of granularities when downsampling datapoints.
Datapoints are inserted only at the highest granularity and are then automatically downsampled in the background, making them ready for efficient querying and visualization.

\begin{figure}
  \centering
  \includegraphics[scale=0.4]{figures/datastream-counter-reset.pdf}
  \caption{Correct rate computation example using the counter derivative operator, automatically derived from two streams.}
  \label{fig:datastream-counter-reset}
\end{figure}

Streams may be automatically computed from other streams using different operators.
The most prominent use of this feature in monitoring is to support correct rate computations under the possibility of counter wraps and resets which could otherwise cause apparent rate spikes when the counter is reset due to a reboot but the system incorrectly classifies it as a counter wrap.
To illustrate why this can be a problem, imagine a simple 8-bit unsigned integer counter (its size is known to the monitoring platform), sampled every 10 seconds (see Figure~\ref{fig:datastream-counter-reset}).
Focusing on the instance where counter value decreases from $212$ to $37$ this can be treated either as a counter wrap (as its maximum value is $255$) or as a counter reset due to device rebooting.
Without additional information, such events must be classified uniformly: if they are classified as wraps, rates may incorrectly spike (in our example the rate would be computed as $(255 - 212 + 37) / 10s = 8.0s^{-1}$); if they are always classified as resets, data points may be lost.

Using datastream, a \textit{counter derivative} operator accepts two streams, one containing raw counter data (for example the number of bytes transferred on a network interface) and one containing discrete events at which a device was rebooted (for example derived from its uptime).
Using both pieces of information, the rate is computed as a derivative, but only when there was no reset event in the last time interval.
In case of a reset, a \texttt{null} value is inserted instead.
However, if there was no reset and the counter value decreased, the event is classified as a counter wrap and the rate is computed using the known maximum value of the counter.
Additional operators include computing sums of multiple streams and automatically deriving reset streams from device uptimes.

The design of datastream is modular, supporting implementations of additional storage backends while continuing to expose the same API.

\subsection{Easy-to-use User Interface}

TODO

notifications
easy to debug
easy to share information about nodes
information keept to date

strict-typing - compiling until there is no errors - you can start with basic router installation and system will be telling you what is wrong and how to fix it and when you fix all errors, you get a working node

but you can also install it through generator

TODO

should we extract some code into external packages like registry and then describe them (registry, datastream, template-overload)?

\section{Evaluation}
\label{sec:evaluation}

TODO

- we should show how an actual deployment looks like in wlan slovenija (a nice schematic figure)
- wlan slovenija, v2, experiences?
- performance comparison, v2 vs. v3?

\section{Conclusion and Future Work}
\label{sec:conclusion}

TODO

- radio planning features

\section*{Acknowledgement}

The authors have been supported by the following institutions: Jernej Kos by the Slovenian Research Agency (Grant 1000-11-310153), by the Shuttleworth Foundation Flash Grant and by the NLnet Foundation (Grant 2014-05-015).

\section*{References}
\bibliography{bibliography/references.bib}

\end{document}
